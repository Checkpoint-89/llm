{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import socket\n",
    "import shutil\n",
    "import gc\n",
    "from importlib import reload\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "from transformers import OPTForCausalLM, AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "import src.setup_embds\n",
    "reload(src.setup_embds)\n",
    "from src.setup_embds import path_to_galactica_folder, path_to_orig_data, path_to_raw_data, path_to_tokenized_data, output_dir\n",
    "from src.setup_embds import ModelClass, checkpoint\n",
    "from src.setup_embds import device\n",
    "from src.setup_embds import make_tensors, make_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk(str(path_to_tokenized_data))\n",
    "\n",
    "model = ModelClass.from_pretrained(str(checkpoint), device_map=\"auto\").base_model\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dirs\n",
    "current_time = time.strftime(\"%b%d_%H-%M-%S\")\n",
    "host = socket.gethostname()\n",
    "_output_dir = Path(path_to_galactica_folder,output_dir,current_time + '_' + host)\n",
    "tensors_file = Path(_output_dir, 'tensors.tsv')\n",
    "metadata_file = Path(_output_dir, 'metadata.tsv')\n",
    "\n",
    "if not _output_dir.exists():\n",
    "    _output_dir.mkdir(parents=True)\n",
    "\n",
    "# copy checkpoint\n",
    "checkpoint_dir = Path(_output_dir, 'checkpoint')\n",
    "if checkpoint_dir.exists():\n",
    "    shutil.rmtree(str(checkpoint_dir))\n",
    "if Path(checkpoint).exists():\n",
    "    shutil.copytree(str(checkpoint), str(checkpoint_dir))\n",
    "else:\n",
    "    model.save_pretrained(str(checkpoint_dir))\n",
    "    tokenizer.save_pretrained(str(checkpoint_dir))\n",
    "\n",
    "dataset = datasets['test'] #.select(range(64))\n",
    "\n",
    "# copy dataset\n",
    "path_to_dataset = Path(_output_dir, 'dataset.json')\n",
    "dataset.save_to_disk(str(path_to_dataset))\n",
    "\n",
    "#copy metadata\n",
    "int2str = {v: k for k,v in (dataset.features['labels']._str2int).items()}\n",
    "metadata = dataset.remove_columns(['input_ids', 'attention_mask', 'token_type_ids'])\n",
    "metadata = metadata.map(lambda seq: {'id': str(seq['id']) }, batched=False)\n",
    "metadata = metadata.map(lambda seq: {'_labels': int2str[seq['labels']] }, batched=False)\n",
    "metadata = metadata.map(lambda seq: {'text': seq['text'].replace('\\t', ' ') }, batched=False)\n",
    "metadata = metadata.map(lambda seq: {'text': seq['text'].replace('\\n', ' ') }, batched=False)\n",
    "metadata.to_csv(str(metadata_file), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors\n",
    "if make_tensors:\n",
    "\n",
    "    dataset = dataset.remove_columns(['id', 'title', 'text', 'token_type_ids', 'labels'])\n",
    "    dataset.set_format(\"torch\")\n",
    "\n",
    "    batch_size = 1\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=batch_size, collate_fn=data_collator)\n",
    "\n",
    "    num_steps = len(dataset) // batch_size\n",
    "    progress_bar = tqdm(range(num_steps))\n",
    "\n",
    "    # Cleaning\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    tensors_f = open(tensors_file, 'w')\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        _batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**_batch)\n",
    "        #outputs = outputs['last_hidden_state'].mean(dim=1)\n",
    "        outputs = outputs['last_hidden_state'][:,-1,:]\n",
    "\n",
    "        for embd in outputs:\n",
    "            embd = [str(e) for e in embd.tolist()]\n",
    "            embd = '\\t'.join(embd)\n",
    "            tensors_f.write(embd + '\\n')\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "    tensors_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galactica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
