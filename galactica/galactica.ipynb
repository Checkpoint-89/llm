{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from importlib import reload\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "from transformers import OPTForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "import utils.preprocess_data\n",
    "reload(utils.preprocess_data)\n",
    "from utils.preprocess_data import preprocess_orig_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up DL framework and device\n",
    "dl_framework = 'pt'\n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "if is_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Set up file and dir paths\n",
    "clean = True # Whether to clean the raw data directory\n",
    "data_type = 'applications' # 'is_experimental' or 'applications'\n",
    "\n",
    "path_to_galactica_folder = Path(r'../galactica')\n",
    "\n",
    "if data_type == 'applications':\n",
    "    path_to_raw = Path(r'./data/raw_applications.json')\n",
    "elif data_type == 'is_experimental':\n",
    "    path_to_raw = Path(r'./data/raw_is_experimental.json')\n",
    "path_to_data = Path(path_to_galactica_folder, path_to_raw)\n",
    "\n",
    "path_to_state_dict = \"./state_dict/model_state_dict.pt\"\n",
    "path_to_state_dict = Path(path_to_state_dict)\n",
    "dir_to_state_dict = path_to_state_dict.parent\n",
    "shutil.rmtree(dir_to_state_dict, ignore_errors=True)\n",
    "os.mkdir(dir_to_state_dict)\n",
    "\n",
    "# Set up checkpoint\n",
    "checkpoint = \"facebook/galactica-125m\"\n",
    "print(\"\\nSet-up completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data to get raw data into /galactica/data\n",
    "if data_type == 'applications':\n",
    "    path_to_orig = Path(r'./data/orig_applications.json')\n",
    "elif data_type == 'is_experimental':\n",
    "    path_to_orig = Path(r'./data/orig_is_experimental.json')\n",
    "\n",
    "preprocess_orig_data(str(path_to_galactica_folder), str(path_to_orig), clean=clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data, model, tokenizer and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "raw_dataset = load_from_disk(str(path_to_data))\n",
    "print(\"\\nDataset loaded: \", raw_dataset)\n",
    "\n",
    "# Get the number of labels\n",
    "num_labels = len(raw_dataset['train'].features['label'].names)\n",
    "print(\"\\nNumber of labels: \", num_labels)\n",
    "\n",
    "# Load the Model\n",
    "#TODO: understand how to properly instantiate the model when device.cuda == 'cuda'\n",
    "model = OPTForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, str(path_to_state_dict))\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    from accelerate import init_empty_weights, load_checkpoint_and_dispatch\n",
    "    config = AutoConfig.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "    with init_empty_weights():\n",
    "        model = OPTForSequenceClassification._from_config(config)\n",
    "    model.tie_weights()\n",
    "    no_split_module_classes = None #List of modules with any residual connection of some kind\n",
    "    model = load_checkpoint_and_dispatch(model, \"./model/model_state_dict.pt\", device_map=\"auto\", no_split_module_classes=no_split_module_classes)\n",
    "print(\"\\nModel instantiated\")\n",
    "\n",
    "# Freeze the model but the last layer\n",
    "# TODO: how to programmatically get the name of the last layer\n",
    "for param in model.named_parameters():\n",
    "    if param[0] != 'score.weight':\n",
    "        param[1].requires_grad = False\n",
    "\n",
    "# TODO: This is probably wrong, check what is the correct max_length\n",
    "max_length = model.config.word_embed_proj_dim\n",
    "print(\"\\nMax length = \", max_length)\n",
    "\n",
    "# Load the Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True) # use_fast is recommended to be False, set to True for testing purposes\n",
    "# use_fast argument; check https://huggingface.co/docs/transformers/model_doc/opt#overview\n",
    "id2label = {i: label for label, i in tokenizer.vocab.items()}\n",
    "pad_token_id = model.config.pad_token_id\n",
    "tokenizer.add_special_tokens({'pad_token': id2label[pad_token_id]})\n",
    "print(\"\\nTokenizer instantiated\")\n",
    "\n",
    "def tokenize_function(sequences):\n",
    "    return tokenizer(sequences['text'], max_length=max_length, truncation=True)\n",
    "\n",
    "#TODO: save the tokenized datasets to disk\n",
    "tokenized_datasets = raw_dataset.map(tokenize_function , batched=True)\n",
    "print(\"\\nTokenized datasets: \", tokenized_datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"\\nDataCollator instantiated\")\n",
    "\n",
    "# Define the TrainingArguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"test-trainer\",\n",
    "    overwrite_output_dir = True, # False\n",
    "    num_train_epochs = 3, # 3\n",
    "    per_device_train_batch_size = 1, # 8\n",
    "    per_device_eval_batch_size = 1, # 8\n",
    "    gradient_accumulation_steps = 1, # 1\n",
    "    learning_rate = 5e-5, # 5e-5\n",
    "    weight_decay = 0, # 0\n",
    "    warmup_steps = 0, # 0\n",
    "    evaluation_strategy = 'no', # 'no'\n",
    "    )\n",
    "print(\"\\nTrainingArguments instantiated\")\n",
    "\n",
    "# Cleaning\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nCleaning done\")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(\"\\nTrainer instantiated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training\n",
    "print(\"\\nStarting training\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galactica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
