{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity(transformers.logging.CRITICAL)\n",
    "\n",
    "import datasets\n",
    "datasets.logging.set_verbosity(datasets.logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(category=FutureWarning ,action='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of ds_builder.info:  <class 'datasets.info.DatasetInfo'>\n",
      "\n",
      "ds_builder.info.description:  Movie Review Dataset.\n",
      "This is a dataset of containing 5,331 positive and 5,331 negative processed\n",
      "sentences from Rotten Tomatoes movie reviews. This data was first used in Bo\n",
      "Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for\n",
      "sentiment categorization with respect to rating scales.'', Proceedings of the\n",
      "ACL, 2005.\n",
      "\n",
      "\n",
      "ds_builder.info.features:  {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"rotten_tomatoes\")\n",
    "\n",
    "print(\"Type of ds_builder.info: \", type(ds_builder.info))\n",
    "print(\"\\nds_builder.info.description: \", ds_builder.info.description)\n",
    "print(\"\\nds_builder.info.features: \", ds_builder.info.features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'validation', 'test']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "\n",
    "get_dataset_split_names(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dataset: <class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 300.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of datasets: <class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading a split returns a Dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "print(f\"type of dataset: {type(dataset)}\")\n",
    "\n",
    "# Loading all returns a DatasetDict\n",
    "datasets = load_dataset(\"rotten_tomatoes\")\n",
    "print(f\"type of datasets: {type(datasets)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets with configurations\n",
    "\n",
    "When a Datasets has several subset, those are called Configurations  \n",
    "One shall select explicitly onee configuration when loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs-CZ', 'de-DE', 'en-AU', 'en-GB', 'en-US', 'es-ES', 'fr-FR', 'it-IT', 'ko-KR', 'nl-NL', 'pl-PL', 'pt-PT', 'ru-RU', 'zh-CN', 'all']\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "configs = get_dataset_config_names(\"PolyAI/minds14\")\n",
    "print(configs)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# mindsFR = load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example:  {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x29B6A72D6D0>, 'label': 6}\n",
      "type(iterable_dataset):  <class 'datasets.iterable_dataset.IterableDataset'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512>,\n",
       "  'label': 6},\n",
       " {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512>,\n",
       "  'label': 6},\n",
       " {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x383>,\n",
       "  'label': 6}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#Get an iterable\n",
    "iterable_dataset = load_dataset(\"food101\", split=\"train\", streaming=True)\n",
    "\n",
    "# Access it one element at a time\n",
    "for example in iterable_dataset:\n",
    "    print(\"This is an example: \", example)\n",
    "    break\n",
    "print(\"type(iterable_dataset): \", type(iterable_dataset))\n",
    "\n",
    "# One get get a subset with take\n",
    "list(iterable_dataset.take(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_format(type=\"torch\", columns=[\"text\", \"label\"])\n",
    "dataset.format['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
